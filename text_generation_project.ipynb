{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python36",
      "language": "python",
      "name": "python36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balaji-0-5/Python/blob/main/text_generation_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f6e6f4a-8547-435c-846b-5a08985992d9"
      },
      "source": [
        "# importing dependencies\n",
        "import numpy\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "id": "0f6e6f4a-8547-435c-846b-5a08985992d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08841693-a4d0-456d-8b82-c94af7febe05",
        "outputId": "299bc64f-60ba-40e5-e1ea-81377a5ee3c3"
      },
      "source": [
        "# downloading stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "id": "08841693-a4d0-456d-8b82-c94af7febe05",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e79a6965-a8bc-46af-aa86-befdf2241acc"
      },
      "source": [
        "# load data\n",
        "# loading data and oipening our input data in the form of a text file\n",
        "# Project Gutenberg is where the data can be found\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/84/84-h/84-h.htm\"\n",
        "req = requests.get(url)\n",
        "content = req.content\n",
        "soup = BeautifulSoup(content,\"html.parser\")\n",
        "file = soup.find('body').text"
      ],
      "id": "e79a6965-a8bc-46af-aa86-befdf2241acc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7479300-7e03-4b0f-8d8e-fbb0e3191061"
      },
      "source": [
        "# tokenization\n",
        "# standardization\n",
        "# What is tokenization ?\n",
        "# Tokenization is the process of breaking a stream of text up into word phrases symbols or other meaningful elements\n",
        "def tokenize_words(input):\n",
        "    # lowercase everything to standardize it\n",
        "    input = input.lower()\n",
        "    #  initiating the tokenizer\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    # tokenizing the text into token \n",
        "    tokens = tokenizer.tokenize(input)\n",
        "    # filtering the stop words into lambda\n",
        "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "# preprocess the input data, make tokens\n",
        "processed_inputs = tokenize_words(file)"
      ],
      "id": "e7479300-7e03-4b0f-8d8e-fbb0e3191061",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09f9dab5-ffb2-4a7c-804a-e3d54b6a6cb5"
      },
      "source": [
        "# chars to numbers\n",
        "# convert characters of our input numbers\n",
        "# we'll sort the list of all characters that appear in out i/p text and then use the enumerate function to get the numbers that represent the characters\n",
        "# we'll then create  a dictionary that stores the keys and values, or the characters and the numbers that represent them \n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "chars_to_num = dict((e,i) for i,e in enumerate(chars))"
      ],
      "id": "09f9dab5-ffb2-4a7c-804a-e3d54b6a6cb5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c22e40bf-fc0e-404a-a6da-ce07887221f9",
        "outputId": "cc33a55b-fe9f-4640-f739-5c37ecd36283"
      },
      "source": [
        "# check if words to chars or chars to nums have worked?\n",
        "# just so we get an idea of what our process of convberting words to characters has worked, we print the length of the variables\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print('Total number of characters :', input_len)\n",
        "print('Total vocab :', vocab_len)"
      ],
      "id": "c22e40bf-fc0e-404a-a6da-ce07887221f9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of characters : 269567\n",
            "Total vocab : 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f4b929c-f431-4c42-a377-ef3b4b76ddc2"
      },
      "source": [
        "# seq length\n",
        "# we'll define how long we want an individual sequence here\n",
        "# an individual sequence is a complete mapping of input characters as integers\n",
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "id": "1f4b929c-f431-4c42-a377-ef3b4b76ddc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c632caa-6359-4771-859b-1404120f2d94",
        "outputId": "f0998b17-e16d-4b1a-80e2-f414c2c252be"
      },
      "source": [
        "# loop through the sequence\n",
        "# here we're going through the entire list of of i/p and converting the chars to numbers with a for loop\n",
        "# this will create a bunch of sequences where each sequence starts with the next character in the i/p data begining with first character\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "    # define i/p and o/p sequences\n",
        "    # i/p length is the current character plus desired sequence length\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "    # out sequence is the initial character plus the total sequence length\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "    # converting the list of characters to integers based on previous values to our lists\n",
        "    x_data.append([chars_to_num[char] for char in in_seq])\n",
        "    y_data.append(chars_to_num[out_seq])\n",
        "\n",
        "# checking to see how many input sequences we have    \n",
        "n_patterns = len(x_data)\n",
        "print('Total Patterns :', n_patterns)"
      ],
      "id": "2c632caa-6359-4771-859b-1404120f2d94",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns : 269467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7118f14-6400-42fc-8a74-31de14bf07b3"
      },
      "source": [
        "# convert input sequence to np array that our network can use \n",
        "x = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "x = x/float(vocab_len)"
      ],
      "id": "a7118f14-6400-42fc-8a74-31de14bf07b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf58850e-6fb6-45c8-bb63-103b3719726c"
      },
      "source": [
        "# one-hot encoding our label data\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "id": "cf58850e-6fb6-45c8-bb63-103b3719726c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b22214d0-f7fa-41cf-819c-6c4d12eeaeae"
      },
      "source": [
        "# creating the model\n",
        "# creating a sequential model\n",
        "# dropout is used to prevent overfitting\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "id": "b22214d0-f7fa-41cf-819c-6c4d12eeaeae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd80d4f0-0b81-4c74-aa53-8a2f9bbe069e"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "id": "dd80d4f0-0b81-4c74-aa53-8a2f9bbe069e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9264b8ca"
      },
      "source": [
        "# saving weights\n",
        "filepath = 'model_weights_saved.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "id": "9264b8ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e170001f",
        "scrolled": true,
        "outputId": "de1d2118-ce8c-48f4-9758-94e19a5701a1"
      },
      "source": [
        "# fit model and let it train\n",
        "model.fit(x, y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
      ],
      "id": "e170001f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1053/1053 [==============================] - 3946s 4s/step - loss: 2.9645\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.91254, saving model to model_weights_saved.hdf5\n",
            "Epoch 2/4\n",
            "1053/1053 [==============================] - 3956s 4s/step - loss: 2.6788\n",
            "\n",
            "Epoch 00002: loss improved from 2.91254 to 2.63719, saving model to model_weights_saved.hdf5\n",
            "Epoch 3/4\n",
            "1053/1053 [==============================] - 3960s 4s/step - loss: 2.5156\n",
            "\n",
            "Epoch 00003: loss improved from 2.63719 to 2.47869, saving model to model_weights_saved.hdf5\n",
            "Epoch 4/4\n",
            "1053/1053 [==============================] - 4009s 4s/step - loss: 2.3813\n",
            "\n",
            "Epoch 00004: loss improved from 2.47869 to 2.35858, saving model to model_weights_saved.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefc54d65d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY5n55dFmndk"
      },
      "source": [
        "# recompile the model with saved weights\n",
        "filename = 'model_weights_saved.hdf5'\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "id": "WY5n55dFmndk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMQftTsRrV6h"
      },
      "source": [
        "# output of the model back to characters\n",
        "num_to_char = dict((i,c) for i,c in enumerate(chars))"
      ],
      "id": "kMQftTsRrV6h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611_on4or2OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d0615a-5b0c-4742-c378-078a74072420"
      },
      "source": [
        "# random seed to help generate\n",
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random seed : \")\n",
        "print('\"', \"\".join([num_to_char[value] for value in pattern]),'\"')"
      ],
      "id": "611_on4or2OB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed : \n",
            "\" ion could express heartfelt sympathy poor william said dear lovely child sleeps angel mother seen br \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HjukHGg96J_",
        "outputId": "59eefdd1-c1cb-4dcb-dfe9-328c38004ab8"
      },
      "source": [
        "# generate the text\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern),1))\n",
        "    x = x/float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "    seq_in = [num_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1 : len(pattern)]"
      ],
      "id": "_HjukHGg96J_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peated seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared seared"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}